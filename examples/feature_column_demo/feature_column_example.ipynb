{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Model building Pipeline using easyflow feature_encoders module"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This module is a fusion between keras layers and tensorflow feature columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "try:\n",
    "    import easyflow\n",
    "except:\n",
    "    ! pip install easy-tensorflow"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# local imports\n",
    "from easyflow.data import TensorflowDataMapper\n",
    "from easyflow.feature_encoders import FeatureColumnTransformer, FeatureUnionTransformer\n",
    "from easyflow.feature_encoders import NumericalFeatureEncoder, EmbeddingFeatureEncoder, CategoricalFeatureEncoder"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "CSV_HEADER = [\n",
    "    \"age\",\n",
    "    \"workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"education\",\n",
    "    \"education_num\",\n",
    "    \"marital_status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"gender\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\",\n",
    "    \"native_country\",\n",
    "    \"income_bracket\",\n",
    "]\n",
    "\n",
    "data_url = (\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    data_frame = pd.read_csv('adult_features.csv')\n",
    "    labels_binary = pd.read_csv('adult_labels.csv')\n",
    "except:\n",
    "    data_frame = pd.read_csv(data_url, header=None, names=CSV_HEADER)\n",
    "    labels = data_frame.pop(\"income_bracket\")\n",
    "    labels_binary = 1.0 * (labels == \" >50K\")\n",
    "    data_frame.to_csv('adult_features.csv', index=False)\n",
    "    labels_binary.to_csv('adult_labels.csv', index=False)\n",
    "\n",
    "print(f\"Train dataset shape: {data_frame.shape}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train dataset shape: (32561, 14)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "batch_size = 256\n",
    "dataset_mapper = TensorflowDataMapper() \n",
    "dataset = dataset_mapper.map(data_frame, labels_binary)\n",
    "\n",
    "train_data_set, val_data_set = dataset_mapper.split_data_set(dataset)\n",
    "train_data_set = train_data_set.batch(batch_size)\n",
    "val_data_set = val_data_set.batch(batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set up the feature encoding list"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "NUMERIC_FEATURE_NAMES = [\n",
    "    \"age\",\n",
    "    \"education_num\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\",\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES_NAMES = [\n",
    "    \"workclass\",\n",
    "    \"marital_status\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"gender\"]\n",
    "\n",
    "EMBEDDING_FEATURES_NAMES = ['education',\n",
    "                            'occupation',\n",
    "                            'native_country']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "feature_encoder_list = [('numerical_features', NumericalFeatureEncoder(), NUMERIC_FEATURE_NAMES),\n",
    "                        ('categorical_features', CategoricalFeatureEncoder(), CATEGORICAL_FEATURES_NAMES),\n",
    "                        ('embedding_features_deep', EmbeddingFeatureEncoder(dimension=10), EMBEDDING_FEATURES_NAMES),\n",
    "                        ('embedding_features_wide', CategoricalFeatureEncoder(), EMBEDDING_FEATURES_NAMES)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting up feature layer and feature encoders"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are two main column transformer classes namely FeatureColumnTransformer and FeatureUnionTransformer. For this example we are going to build a Wide and Deep model architecture. So we will be using the FeatureColumnTransformer since it gives us more flexibility. FeatureUnionTransformer concatenates all the features in the input layer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "feature_layer_inputs, feature_layer =  FeatureColumnTransformer(feature_encoder_list).transform(train_data_set)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "deep = tf.keras.layers.concatenate([feature_layer['numerical_features'],\n",
    "                                    feature_layer['categorical_features'],\n",
    "                                    feature_layer['embedding_features_deep']])\n",
    "\n",
    "wide = feature_layer['embedding_features_wide']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "deep = tf.keras.layers.BatchNormalization()(deep)\n",
    "\n",
    "for nodes in [128, 64, 32]:\n",
    "    deep = tf.keras.layers.Dense(nodes, activation='relu')(deep)\n",
    "    deep = tf.keras.layers.Dropout(0.5)(deep)\n",
    "\n",
    "# combine wide and deep layers\n",
    "wide_and_deep = tf.keras.layers.concatenate([deep, wide])\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(wide_and_deep)\n",
    "model = tf.keras.Model(inputs=[v for v in feature_layer_inputs.values()], outputs=output)\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.0),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'), tf.keras.metrics.AUC(name='auc')])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "model.fit(train_data_set, validation_data=val_data_set, epochs=10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save and load model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "model.save(filepath='tfcolumn_model_example')\n",
    "del model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "loaded_model = tf.keras.models.load_model(\"tfcolumn_model_example\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "loaded_model.predict(val_data_set.take(1))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.9 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}