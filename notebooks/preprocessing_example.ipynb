{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Encoder, Pipeline, SequentialEncoder and FeatureUnion example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easyflow.preprocessing module contains functionality similar to what sklearn does with its Pipeline, FeatureUnion and ColumnTransformer does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization, CategoryEncoding, StringLookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local imports\n",
    "from easyflow.data.mapper import TensorflowDataMapper\n",
    "from easyflow.preprocessing.preprocessor import Encoder, Pipeline, SequentialEncoder, FeatureUnion\n",
    "from easyflow.preprocessing.custom import IdentityPreprocessingLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data and map as tf.data.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the TensorflowDataMapper class to map pandas data frame to a tf.data.Dataset type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n",
    "dataframe = pd.read_csv(file_url)\n",
    "dataframe = dataframe.copy()\n",
    "labels = dataframe.pop(\"target\")\n",
    "\n",
    "batch_size = 32\n",
    "dataset_mapper = TensorflowDataMapper() \n",
    "dataset = dataset_mapper.map(dataframe, labels)\n",
    "train_data_set, val_data_set = dataset_mapper.split_data_set(dataset)\n",
    "train_data_set = train_data_set.batch(batch_size)\n",
    "val_data_set = val_data_set.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>fixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>reversible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
       "\n",
       "   ca        thal  \n",
       "0   0       fixed  \n",
       "1   3      normal  \n",
       "2   2  reversible  \n",
       "3   0      normal  \n",
       "4   0      normal  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_FEATURES = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'slope']\n",
    "CATEGORICAL_FEATURES = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'ca']\n",
    "# thal is represented as a string\n",
    "STRING_CATEGORICAL_FEATURES = ['thal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Preprocessing layer using FeatureUnion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Encoder and SequentialEncoder to preprocess features by putting everything in a FeatureUnion object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_encoder_list = [\n",
    "                        Encoder([('numeric_encoder', Normalization, NUMERICAL_FEATURES)]),\n",
    "                        Encoder([('categorical_encoder', CategoryEncoding, CATEGORICAL_FEATURES)]),\n",
    "                        # For feature thal we first need to run StringLookup followed by a CategoryEncoding layer\n",
    "                        SequentialEncoder([('string_encoder', StringLookup, STRING_CATEGORICAL_FEATURES),\n",
    "                                           ('categorical_encoder', CategoryEncoding, STRING_CATEGORICAL_FEATURES)])\n",
    "                        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = FeatureUnion(feature_encoder_list)\n",
    "all_feature_inputs, preprocessing_layer = encoder.encode(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concatenate/concat:0\", shape=(None, 31), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(preprocessing_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "# setup simple network\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(preprocessing_layer)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inputs=all_feature_inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'), tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.6361 - accuracy: 0.6123 - auc: 0.6322 - val_loss: 0.5864 - val_accuracy: 0.7368 - val_auc: 0.7014\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5796 - accuracy: 0.7048 - auc: 0.6562 - val_loss: 0.5326 - val_accuracy: 0.7237 - val_auc: 0.8596\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5599 - accuracy: 0.7181 - auc: 0.7032 - val_loss: 0.4977 - val_accuracy: 0.7763 - val_auc: 0.8385\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4835 - accuracy: 0.7974 - auc: 0.7897 - val_loss: 0.4257 - val_accuracy: 0.8026 - val_auc: 0.9130\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.8018 - auc: 0.8220 - val_loss: 0.4792 - val_accuracy: 0.7763 - val_auc: 0.8417\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8150 - auc: 0.8655 - val_loss: 0.3951 - val_accuracy: 0.8158 - val_auc: 0.9447\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8018 - auc: 0.8738 - val_loss: 0.4362 - val_accuracy: 0.7500 - val_auc: 0.8851\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.7841 - auc: 0.8715 - val_loss: 0.4386 - val_accuracy: 0.7763 - val_auc: 0.8708\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3813 - accuracy: 0.8238 - auc: 0.8890 - val_loss: 0.4252 - val_accuracy: 0.7763 - val_auc: 0.8927\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.8326 - auc: 0.8866 - val_loss: 0.4193 - val_accuracy: 0.7763 - val_auc: 0.8708\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_data_set, validation_data=val_data_set, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More flexibility with Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FeatureUnion subclasses Pipeline and concatenates(i.e union) the layers. For more flexibility like a wide and deep neural network, Pipeline class will give you more flexibility in that sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_encoder_list = [\n",
    "                        Encoder([('numeric_encoder', Normalization, NUMERICAL_FEATURES)]),\n",
    "                        Encoder([('categorical_encoder', CategoryEncoding, CATEGORICAL_FEATURES)]),\n",
    "                        # For feature thal we first need to run StringLookup followed by a CategoryEncoding layer\n",
    "                        SequentialEncoder([('string_encoder', StringLookup, STRING_CATEGORICAL_FEATURES),\n",
    "                                           ('categorical_encoder', CategoryEncoding, STRING_CATEGORICAL_FEATURES)])\n",
    "                        ]\n",
    "\n",
    "encoder = Pipeline(feature_encoder_list)\n",
    "all_feature_inputs1, preprocessing_layer1 = encoder.encode(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concatenate/concat:0\", shape=(None, 31), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(preprocessing_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
