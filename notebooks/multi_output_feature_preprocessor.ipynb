{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c661b3e",
   "metadata": {},
   "source": [
    "# Single Input Multiple Output Preprocessing Layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e899832",
   "metadata": {},
   "source": [
    "<img src=\"preprocessing.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "*Image taken from https://blog.tensorflow.org/2021/11/an-introduction-to-keras-preprocessing.html*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db2b4f0",
   "metadata": {},
   "source": [
    "In this example we will show case how to apply different transformations and preprocessing steps on the same feature. What we have here is an example of a **Single input Multiple output** feature transformation scenario.\n",
    "\n",
    "This is what the feature transformation `Pipeline` looks like:\n",
    "\n",
    "                                            Feature\n",
    "                                              /  \\\n",
    "                                             /    \\\n",
    "                                            /      \\\n",
    "                                           /        \\\n",
    "                                      Transform1 Transform2\n",
    "                                             \\    /\n",
    "                                              \\  /\n",
    "                                               \\/\n",
    "                                     Concat into a Single Layer\n",
    "\n",
    "We will be utilizing a library called `easyflow` which implements feature transformation pipelines natively implemented in Keras (https://pypi.org/project/easy-tensorflow/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ecba172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from easyflow.preprocessing.pipeline import FeatureUnion\n",
    "from easyflow.preprocessing import (FeatureInputLayer,\n",
    "                                    PreprocessorChain,\n",
    "                                    MultiOutputTransformer\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddd20fe",
   "metadata": {},
   "source": [
    "For our example we will use the imdb reviews dataset. The steps here is similar to the preprocessing example on th Tensorflow blog: https://blog.tensorflow.org/2021/11/an-introduction-to-keras-preprocessing.html. We will however make use of the Feature Preprocessing and Transformation Pipelines from the `easyflow` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00abce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tfds.load('imdb_reviews', split='train', as_supervised=True).batch(32)\n",
    "train_ds = train_ds.map(lambda x, y: ({'review': x}, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027b0d24",
   "metadata": {},
   "source": [
    "# Create Feature transformation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6610f5",
   "metadata": {},
   "source": [
    "Lets create our feature transformation Pipeline. For this example we only have one raw feature; `review` . The transformations that we will be applying is:\n",
    "\n",
    "1) TextVectorization as one step and;\\\n",
    "2) Another step transforming text to the length of the review and than normalizing it.\n",
    "\n",
    "These steps will be concatenated in our final output layer. The transformation layer we will be using is a custom layer implemented in `easyflow` namely `MultiOutputPreprocessor` . This layer takes as input a list of independent preprocessing or transformation steps (composed of layers) that will be applied on the giving feature. `MultiOutputTransformer` is used as a step in `FeaturePreprocessor` and `FeatureUnion` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92338be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 18:04:23.129960: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "def TextLengthPipeline():\n",
    "    \"\"\"Create a sequential Pipeline to compute length followed by normalising feature\n",
    "    \"\"\"\n",
    "    return PreprocessorChain([\n",
    "        tf.keras.layers.Lambda(lambda x: tf.strings.length(x)),\n",
    "        tf.keras.layers.Normalization()\n",
    "    ])\n",
    "\n",
    "steps = MultiOutputTransformer([\n",
    "    # transform 1: create multi hot encoder\n",
    "    tf.keras.layers.TextVectorization(output_mode='multi_hot', max_tokens=2500),\n",
    "    # transform 2: get the length of the review\n",
    "    TextLengthPipeline()\n",
    "])\n",
    "\n",
    "pipeline = FeatureUnion([\n",
    "    ('review', steps, ['review'])\n",
    "])\n",
    "\n",
    "pipeline.adapt(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e861ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer_inputs = FeatureInputLayer(\n",
    "    {'review': tf.string}\n",
    ")\n",
    "\n",
    "preprocessed_inputs = pipeline(feature_layer_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ea7c5d",
   "metadata": {},
   "source": [
    "Next we will use the common pattern for training by creating a model that applies the preprocessing to speed up training. When we start from raw data as in our example. We need to preprocess all string operations on the CPU and than feed that to a GPU. Preprocessing is also not something that we train and it is independent from the forward pass. This will reduce our throughput as the GPU will be idle while waiting for data. To speed things up we will prefetch batches of preprocessed data. This will ensure that while we processing batch of data on the GPU the CPU is getting the next batch of preprocessed data ready.\n",
    "\n",
    "<img src=\"gpu_cpu_gaps.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "*Image taken from https://www.tensorflow.org*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d610390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our preprocessing model\n",
    "preprocessing_model = tf.keras.Model(feature_layer_inputs, preprocessed_inputs)\n",
    "\n",
    "# create training model that will be applied on the forward pass\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(preprocessed_inputs)\n",
    "training_model = tf.keras.Model(preprocessed_inputs, outputs)\n",
    "training_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'), tf.keras.metrics.AUC(name='auc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cb6ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_ds = train_ds.map(\n",
    "    lambda x, y: (preprocessing_model(x), y),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdb898b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 1s 576us/step - loss: 0.4627 - accuracy: 0.8183 - auc: 0.9018\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 0s 554us/step - loss: 0.3307 - accuracy: 0.8768 - auc: 0.9471\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 0s 557us/step - loss: 0.2942 - accuracy: 0.8880 - auc: 0.9550\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 0s 549us/step - loss: 0.2753 - accuracy: 0.8931 - auc: 0.9591\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 0s 554us/step - loss: 0.2634 - accuracy: 0.8980 - auc: 0.9617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1753c84f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_model.fit(preprocessed_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2246c380",
   "metadata": {},
   "source": [
    "This gives as nice speed improvement. Our utilization graph will look something like this:\n",
    "\n",
    "<img src=\"full_utilization.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "*Image taken from https://www.tensorflow.org*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
