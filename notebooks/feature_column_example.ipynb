{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building Pipeline using easyflow feature_encoders module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module is a fusion between keras layers and tensorflow feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local imports\n",
    "from easyflow.data.mapper import TensorflowDataMapper\n",
    "from easyflow.feature_encoders.transformer import FeatureColumnTransformer, FeatureUnionTransformer\n",
    "from easyflow.feature_encoders.feature_encoder import NumericalFeatureEncoder, EmbeddingFeatureEncoder, CategoricalFeatureEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (32561, 14)\n"
     ]
    }
   ],
   "source": [
    "CSV_HEADER = [\n",
    "    \"age\",\n",
    "    \"workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"education\",\n",
    "    \"education_num\",\n",
    "    \"marital_status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"gender\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\",\n",
    "    \"native_country\",\n",
    "    \"income_bracket\",\n",
    "]\n",
    "\n",
    "data_url = (\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    data_frame = pd.read_csv('adult_features.csv')\n",
    "    labels_binary = pd.read_csv('adult_labels.csv')\n",
    "except:\n",
    "    data_frame = pd.read_csv(data_url, header=None, names=CSV_HEADER)\n",
    "    labels = data_frame.pop(\"income_bracket\")\n",
    "    labels_binary = 1.0 * (labels == \" >50K\")\n",
    "    data_frame.to_csv('adult_features.csv', index=False)\n",
    "    labels_binary.to_csv('adult_labels.csv', index=False)\n",
    "\n",
    "print(f\"Train dataset shape: {data_frame.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "dataset_mapper = TensorflowDataMapper() \n",
    "dataset = dataset_mapper.map(data_frame, labels_binary)\n",
    "\n",
    "train_data_set, val_data_set = dataset_mapper.split_data_set(dataset)\n",
    "train_data_set = train_data_set.batch(batch_size)\n",
    "val_data_set = val_data_set.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the feature encoding list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_FEATURE_NAMES = [\n",
    "    \"age\",\n",
    "    \"education_num\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\",\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES_NAMES = [\n",
    "    \"workclass\",\n",
    "    \"marital_status\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"gender\"]\n",
    "\n",
    "EMBEDDING_FEATURES_NAMES = ['education',\n",
    "                            'occupation',\n",
    "                            'native_country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_encoder_list = [('numerical_features', NumericalFeatureEncoder(), NUMERIC_FEATURE_NAMES),\n",
    "                        ('categorical_features', CategoricalFeatureEncoder(), CATEGORICAL_FEATURES_NAMES),\n",
    "                        ('embedding_features_deep', EmbeddingFeatureEncoder(), EMBEDDING_FEATURES_NAMES),\n",
    "                        ('embedding_features_wide', CategoricalFeatureEncoder(), EMBEDDING_FEATURES_NAMES)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up feature layer and feature encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main column transformer classes namely FeatureColumnTransformer and FeatureUnionTransformer. For this example we are going to build a Wide and Deep model architecture. So we will be using the FeatureColumnTransformer since it gives us more flexibility. FeatureUnionTransformer concatenates all the features in the input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer_inputs, feature_encoders =  FeatureColumnTransformer(feature_encoder_list).transform(train_data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_features = feature_encoders['numerical_features']+\\\n",
    "                feature_encoders['categorical_features']+\\\n",
    "                feature_encoders['embedding_features_deep']\n",
    "\n",
    "wide_features = feature_encoders['embedding_features_wide']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep = tf.keras.layers.DenseFeatures(deep_features)(feature_layer_inputs)\n",
    "deep = tf.keras.layers.BatchNormalization()(deep)\n",
    "\n",
    "wide = tf.keras.layers.DenseFeatures(wide_features)(feature_layer_inputs)\n",
    "\n",
    "for nodes in [128, 64, 32]:\n",
    "    deep = tf.keras.layers.Dense(nodes, activation='relu')(deep)\n",
    "    deep = tf.keras.layers.Dropout(0.5)(deep)\n",
    "\n",
    "wide_and_deep = tf.keras.layers.concatenate([deep, wide])\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(wide_and_deep)\n",
    "model = tf.keras.Model(inputs=[v for v in feature_layer_inputs.values()], outputs=output)\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.0),\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'), tf.keras.metrics.AUC(name='auc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:543: UserWarning: Input dict contained keys ['fnlwgt'] which did not match any model input. They will be ignored by the model.\n",
      "  [n for n in tensors.keys() if n not in ref_input_names])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 2s 17ms/step - loss: 0.4817 - accuracy: 0.7550 - auc: 0.7550 - val_loss: 0.5554 - val_accuracy: 0.6660 - val_auc: 0.8772\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.3782 - accuracy: 0.8252 - auc: 0.8694 - val_loss: 0.4102 - val_accuracy: 0.7885 - val_auc: 0.8934\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.3645 - accuracy: 0.8320 - auc: 0.8801 - val_loss: 0.3445 - val_accuracy: 0.8382 - val_auc: 0.9038\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 1s 9ms/step - loss: 0.3535 - accuracy: 0.8381 - auc: 0.8868 - val_loss: 0.3282 - val_accuracy: 0.8482 - val_auc: 0.9057\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.3463 - accuracy: 0.8431 - auc: 0.8921 - val_loss: 0.3240 - val_accuracy: 0.8521 - val_auc: 0.9086\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 1s 11ms/step - loss: 0.3478 - accuracy: 0.8433 - auc: 0.8900 - val_loss: 0.3094 - val_accuracy: 0.8548 - val_auc: 0.9129\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.3356 - accuracy: 0.8484 - auc: 0.8972 - val_loss: 0.3139 - val_accuracy: 0.8527 - val_auc: 0.9148\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.3325 - accuracy: 0.8497 - auc: 0.9002 - val_loss: 0.3134 - val_accuracy: 0.8537 - val_auc: 0.9123\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.3307 - accuracy: 0.8500 - auc: 0.9012 - val_loss: 0.3138 - val_accuracy: 0.8538 - val_auc: 0.9158\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 1s 10ms/step - loss: 0.3341 - accuracy: 0.8480 - auc: 0.9010 - val_loss: 0.3095 - val_accuracy: 0.8531 - val_auc: 0.9144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5ebd19c358>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data_set, validation_data=val_data_set, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
