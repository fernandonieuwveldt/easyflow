{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building Pipeline using easyflow feature_encoders module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module is a fusion between keras layers and tensorflow feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local imports\n",
    "from easyflow.data import TensorflowDataMapper\n",
    "from easyflow.feature_encoders import FeatureColumnTransformer, FeatureUnionTransformer\n",
    "from easyflow.feature_encoders import NumericalFeatureEncoder, EmbeddingFeatureEncoder, CategoricalFeatureEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (32561, 14)\n"
     ]
    }
   ],
   "source": [
    "CSV_HEADER = [\n",
    "    \"age\",\n",
    "    \"workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"education\",\n",
    "    \"education_num\",\n",
    "    \"marital_status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"gender\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\",\n",
    "    \"native_country\",\n",
    "    \"income_bracket\",\n",
    "]\n",
    "\n",
    "data_url = (\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    data_frame = pd.read_csv('adult_features.csv')\n",
    "    labels_binary = pd.read_csv('adult_labels.csv')\n",
    "except:\n",
    "    data_frame = pd.read_csv(data_url, header=None, names=CSV_HEADER)\n",
    "    labels = data_frame.pop(\"income_bracket\")\n",
    "    labels_binary = 1.0 * (labels == \" >50K\")\n",
    "    data_frame.to_csv('adult_features.csv', index=False)\n",
    "    labels_binary.to_csv('adult_labels.csv', index=False)\n",
    "\n",
    "print(f\"Train dataset shape: {data_frame.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "dataset_mapper = TensorflowDataMapper() \n",
    "dataset = dataset_mapper.map(data_frame, labels_binary)\n",
    "\n",
    "train_data_set, val_data_set = dataset_mapper.split_data_set(dataset)\n",
    "train_data_set = train_data_set.batch(batch_size)\n",
    "val_data_set = val_data_set.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the feature encoding list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_FEATURE_NAMES = [\n",
    "    \"age\",\n",
    "    \"education_num\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\",\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES_NAMES = [\n",
    "    \"workclass\",\n",
    "    \"marital_status\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"gender\"]\n",
    "\n",
    "EMBEDDING_FEATURES_NAMES = ['education',\n",
    "                            'occupation',\n",
    "                            'native_country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_encoder_list = [('numerical_features', NumericalFeatureEncoder(), NUMERIC_FEATURE_NAMES),\n",
    "                        ('categorical_features', CategoricalFeatureEncoder(), CATEGORICAL_FEATURES_NAMES),\n",
    "                        ('embedding_features_deep', EmbeddingFeatureEncoder(dimension=10), EMBEDDING_FEATURES_NAMES),\n",
    "                        ('embedding_features_wide', CategoricalFeatureEncoder(), EMBEDDING_FEATURES_NAMES)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up feature layer and feature encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main column transformer classes namely FeatureColumnTransformer and FeatureUnionTransformer. For this example we are going to build a Wide and Deep model architecture. So we will be using the FeatureColumnTransformer since it gives us more flexibility. FeatureUnionTransformer concatenates all the features in the input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer_inputs, feature_layer =  FeatureColumnTransformer(feature_encoder_list).transform(train_data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numerical_features': <KerasTensor: shape=(None, 5) dtype=float32 (created by layer 'dense_features_4')>,\n",
       " 'categorical_features': <KerasTensor: shape=(None, 29) dtype=float32 (created by layer 'dense_features_5')>,\n",
       " 'embedding_features_deep': <KerasTensor: shape=(None, 30) dtype=float32 (created by layer 'dense_features_6')>,\n",
       " 'embedding_features_wide': <KerasTensor: shape=(None, 73) dtype=float32 (created by layer 'dense_features_7')>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep = tf.keras.layers.concatenate([feature_layer['numerical_features'],\n",
    "                                    feature_layer['categorical_features'],\n",
    "                                    feature_layer['embedding_features_deep']])\n",
    "\n",
    "wide = feature_layer['embedding_features_wide']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep = tf.keras.layers.BatchNormalization()(deep)\n",
    "\n",
    "for nodes in [128, 64, 32]:\n",
    "    deep = tf.keras.layers.Dense(nodes, activation='relu')(deep)\n",
    "    deep = tf.keras.layers.Dropout(0.5)(deep)\n",
    "\n",
    "wide_and_deep = tf.keras.layers.concatenate([deep, wide])\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(wide_and_deep)\n",
    "model = tf.keras.Model(inputs=[v for v in feature_layer_inputs.values()], outputs=output)\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.0),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'), tf.keras.metrics.AUC(name='auc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data_set, validation_data=val_data_set, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
